{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bf8d2f",
   "metadata": {},
   "source": [
    "# <center> **How to use MOABB and how to validate any algorithm** </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc6f7f",
   "metadata": {},
   "source": [
    "The Mother of All BCI Benchmarks (MOABB) is a python library that comprehends all free popular Brain-Computer Interface (BCI) EEG datasets to validate any algorithm for BCIs. Brain-Computer Interface are devices that allows to control by using brain signals, for this, is possible to model different algorithms based on brain data to classify theses signals. After modeling, these algorithms must be validated, in order to know if they are able to accurately predict the brain signal. \n",
    "\n",
    "At first, sounds easy to train and validate theses models to classify brain signals, but due to non-stacionary and low Signal-To-Noise (SNR) features of the brain signals recorded by Electroencefalogran (EEG), is pretty difficult to model algorithms that can generalize for different multiple different trials, subjects and sessions. When fresh research about BCI shows the results of an new algorithm that can performn well compared to others, it lacks of generalization between subjects. And when some reasechers tries to use multiple datasets to validate its model, its is very dificult, due to necessity of different *pipelines* to process the data.\n",
    "\n",
    "To solve this issue [1] developed an python library that has many free EEG datasets that be used to validate an new classification model of brain signals. Is this tutorial will shown how to use this library to validate your own algorithm to classify brain signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08ba09",
   "metadata": {},
   "source": [
    "## **1. Installing MOABB**\n",
    "\n",
    "To install this library is necessary to have Python version 3.8+ already installed on your machine `python==3.8+`, and Pip package installer. With this prerequisite satified, execute following command on your terminal: `pip install moabb`. It is also possible to execute command on the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install moabb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35674ad4",
   "metadata": {},
   "source": [
    "Installing MOABB will automatically install necessary libraries to manipulate data, such as `MNE` and `numpy`. If you and to Guarrantee that all libraries were installed you can also execute the previous command for `numpy` and `mne`, just need to basically: `pip install <package>`, were `<package>` if the name of the library you want to install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install mne numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af8696",
   "metadata": {},
   "source": [
    "## **2. Importing Libraries**\n",
    "\n",
    "After installing necessary, we must import them to be usable, using `import`. In our case will be using `import moabb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02da1733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erika\\Documents\\Code\\eeg-pyriemann-pipeline\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy\n",
    "import moabb\n",
    "\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e17b63",
   "metadata": {},
   "source": [
    "## **3. Datasets available**\n",
    "\n",
    "The datasets available in this library are separeted by EEG paradigms, such as **Imagery**, **P300**, **State Steady Visual Evoked Potentials (SSVEP)**, **CVEP** and **Resting State**. It is possible to visualize all dataset available by printing `moabb.datasets.utils.dataset_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed001f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all dataset\n",
    "all_datasets = copy.copy(moabb.datasets.utils.dataset_list) # Getting a copy for data safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74abc164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets: 77\n",
      "[<class 'moabb.datasets.alex_mi.AlexMI'>, <class 'moabb.datasets.braininvaders.BI2012'>, <class 'moabb.datasets.braininvaders.BI2013a'>, <class 'moabb.datasets.braininvaders.BI2014a'>, <class 'moabb.datasets.braininvaders.BI2014b'>, <class 'moabb.datasets.braininvaders.BI2015a'>, <class 'moabb.datasets.braininvaders.BI2015b'>, <class 'moabb.datasets.bnci.BNCI2014001'>, <class 'moabb.datasets.bnci.BNCI2014002'>, <class 'moabb.datasets.bnci.BNCI2014004'>, <class 'moabb.datasets.bnci.BNCI2014008'>, <class 'moabb.datasets.bnci.BNCI2014009'>, <class 'moabb.datasets.bnci.BNCI2014_001'>, <class 'moabb.datasets.bnci.BNCI2014_002'>, <class 'moabb.datasets.bnci.BNCI2014_004'>, <class 'moabb.datasets.bnci.BNCI2014_008'>, <class 'moabb.datasets.bnci.BNCI2014_009'>, <class 'moabb.datasets.bnci.BNCI2015001'>, <class 'moabb.datasets.bnci.BNCI2015003'>, <class 'moabb.datasets.bnci.BNCI2015004'>, <class 'moabb.datasets.bnci.BNCI2015_001'>, <class 'moabb.datasets.bnci.BNCI2015_003'>, <class 'moabb.datasets.bnci.BNCI2015_004'>, <class 'moabb.datasets.castillos2023.CastillosBurstVEP100'>, <class 'moabb.datasets.castillos2023.CastillosBurstVEP40'>, <class 'moabb.datasets.castillos2023.CastillosCVEP100'>, <class 'moabb.datasets.castillos2023.CastillosCVEP40'>, <class 'moabb.datasets.phmd_ml.Cattan2019_PHMD'>, <class 'moabb.datasets.braininvaders.Cattan2019_VR'>, <class 'moabb.datasets.gigadb.Cho2017'>, <class 'moabb.datasets.neiry.DemonsP300'>, <class 'moabb.datasets.epfl.EPFLP300'>, <class 'moabb.datasets.erpcore2021.ErpCore2021_ERN'>, <class 'moabb.datasets.erpcore2021.ErpCore2021_LRP'>, <class 'moabb.datasets.erpcore2021.ErpCore2021_MMN'>, <class 'moabb.datasets.erpcore2021.ErpCore2021_N170'>, <class 'moabb.datasets.erpcore2021.ErpCore2021_N2pc'>, <class 'moabb.datasets.erpcore2021.ErpCore2021_N400'>, <class 'moabb.datasets.erpcore2021.ErpCore2021_P3'>, <class 'moabb.datasets.fake.FakeDataset'>, <class 'moabb.datasets.fake.FakeVirtualRealityDataset'>, <class 'moabb.datasets.mpi_mi.GrosseWentrup2009'>, <class 'moabb.datasets.phmd_ml.HeadMountedDisplay'>, <class 'moabb.datasets.hinss2021.Hinss2021'>, <class 'moabb.datasets.huebner_llp.Huebner2017'>, <class 'moabb.datasets.huebner_llp.Huebner2018'>, <class 'moabb.datasets.ssvep_exo.Kalunga2016'>, <class 'moabb.datasets.Lee2019.Lee2019_ERP'>, <class 'moabb.datasets.Lee2019.Lee2019_MI'>, <class 'moabb.datasets.Lee2019.Lee2019_SSVEP'>, <class 'moabb.datasets.liu2024.Liu2024'>, <class 'moabb.datasets.ssvep_mamem.MAMEM1'>, <class 'moabb.datasets.ssvep_mamem.MAMEM2'>, <class 'moabb.datasets.ssvep_mamem.MAMEM3'>, <class 'moabb.datasets.mpi_mi.MunichMI'>, <class 'moabb.datasets.ssvep_nakanishi.Nakanishi2015'>, <class 'moabb.datasets.upper_limb.Ofner2017'>, <class 'moabb.datasets.physionet_mi.PhysionetMI'>, <class 'moabb.datasets.alphawaves.Rodrigues2017'>, <class 'moabb.datasets.ssvep_exo.SSVEPExo'>, <class 'moabb.datasets.schirrmeister2017.Schirrmeister2017'>, <class 'moabb.datasets.bbci_eeg_fnirs.Shin2017A'>, <class 'moabb.datasets.bbci_eeg_fnirs.Shin2017B'>, <class 'moabb.datasets.sosulski2019.Sosulski2019'>, <class 'moabb.datasets.stieger2021.Stieger2021'>, <class 'moabb.datasets.thielen2015.Thielen2015'>, <class 'moabb.datasets.thielen2021.Thielen2021'>, <class 'moabb.datasets.braininvaders.VirtualReality'>, <class 'moabb.datasets.ssvep_wang.Wang2016'>, <class 'moabb.datasets.Weibo2014.Weibo2014'>, <class 'moabb.datasets.Zhou2016.Zhou2016'>, <class 'moabb.datasets.braininvaders.bi2012'>, <class 'moabb.datasets.braininvaders.bi2013a'>, <class 'moabb.datasets.braininvaders.bi2014a'>, <class 'moabb.datasets.braininvaders.bi2014b'>, <class 'moabb.datasets.braininvaders.bi2015a'>, <class 'moabb.datasets.braininvaders.bi2015b'>]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of datasets: {len(all_datasets)}\")\n",
    "print(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541ad399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AlexMI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets[0].__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97817c",
   "metadata": {},
   "source": [
    "It is also possible to select these datasets by its paradigm, it is possible to do this by using `moabb.datasets.utils.dataset_search()` function, where we can pass some parameters to select the perfect dataset we want, one of these parameters is `paradigm`, which can be `'imagery'`, `'p300'`, `'ssvep'` and `'cvep'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76cef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting SSVEP paradigm\n",
    "ssvep_datasets = copy.deepcopy(moabb.datasets.utils.dataset_search(paradigm='ssvep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db68c1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SSVEP datasets: 7\n",
      "[<moabb.datasets.ssvep_exo.Kalunga2016 object at 0x0000019C3560D8D0>, <moabb.datasets.Lee2019.Lee2019_SSVEP object at 0x0000019C3560D960>, <moabb.datasets.ssvep_mamem.MAMEM1 object at 0x0000019C3560D900>, <moabb.datasets.ssvep_mamem.MAMEM2 object at 0x0000019C3560DAE0>, <moabb.datasets.ssvep_mamem.MAMEM3 object at 0x0000019C3560F550>, <moabb.datasets.ssvep_nakanishi.Nakanishi2015 object at 0x0000019C3560DA50>, <moabb.datasets.ssvep_wang.Wang2016 object at 0x0000019C3560DBA0>]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of SSVEP datasets: {len(ssvep_datasets)}\")\n",
    "print(ssvep_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f0789",
   "metadata": {},
   "source": [
    "In the function `moabb.datasets.utils.dataset_search()` there are other parameters to filter, such as: \n",
    "* `multi_session` - Returns just the datasets that that has more than one session per subject.\n",
    "* `events` - Type of event to select.\n",
    "* `has_all_events` - Select dataset with all types of events.\n",
    "* `interval` - (Motor Imagery Only) minimal time length of the event.\n",
    "* `min_subjects` - Minum number of subjects in an dataset.\n",
    "* `channels` - List of channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94753c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<moabb.datasets.bnci.BNCI2015_001 at 0x20b9034dab0>,\n",
       " <moabb.datasets.fake.FakeDataset at 0x20b9034cc70>,\n",
       " <moabb.datasets.Lee2019.Lee2019_MI at 0x20bdb2dd2d0>,\n",
       " <moabb.datasets.bbci_eeg_fnirs.Shin2017A at 0x20b8ee01180>,\n",
       " <moabb.datasets.stieger2021.Stieger2021 at 0x20bdc2e4040>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moabb.datasets.utils.dataset_search(paradigm='imagery',\n",
    "                                    multi_session=True,\n",
    "                                    min_subjects=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf757d",
   "metadata": {},
   "source": [
    "It also possible to create fake dataset using Python library `fake` [2]. When used the functions used above, it shows class `moabb.datasets.fake.FakeDataset()`, which is a class implemented for test purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = moabb.datasets.fake.FakeDataset(event_list=['fake1', 'fake2'],\n",
    "                                            n_sessions=2,\n",
    "                                            n_runs=2,\n",
    "                                            paradigm='imagery',\n",
    "                                            channels=('C3', 'Cz', 'C4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2dacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fake_data.get_data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a2b6a",
   "metadata": {},
   "source": [
    "## **4. Main Concepts**\n",
    "\n",
    "Before diving into how to use these datasets to create an pipeline, it is important to know the four main concepts of the MOABB: (1) Datasets, (2) Paradigms, (3) Evaluation, and (4) Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e127f4d",
   "metadata": {},
   "source": [
    "### **4.1 Datasets**\n",
    "\n",
    "Since we already know how to seach and select desired datasets, we'll start selecting dataset for `imagery` paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7fe6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all datasets with motor imagery\n",
    "imagery_datasets = copy.copy(moabb.datasets.utils.dataset_search(paradigm='imagery'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aba0530c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<moabb.datasets.alex_mi.AlexMI at 0x19c3560d870>,\n",
       " <moabb.datasets.bnci.BNCI2014_001 at 0x19c3560db10>,\n",
       " <moabb.datasets.bnci.BNCI2014_002 at 0x19c3560efb0>,\n",
       " <moabb.datasets.bnci.BNCI2014_004 at 0x19c3560c490>,\n",
       " <moabb.datasets.bnci.BNCI2015_001 at 0x19c3560ef50>,\n",
       " <moabb.datasets.bnci.BNCI2015_004 at 0x19c3560c430>,\n",
       " <moabb.datasets.gigadb.Cho2017 at 0x19c3560dc30>,\n",
       " <moabb.datasets.fake.FakeDataset at 0x19c3560dc90>,\n",
       " <moabb.datasets.mpi_mi.GrosseWentrup2009 at 0x19c016c1720>,\n",
       " <moabb.datasets.Lee2019.Lee2019_MI at 0x19c016c3ee0>,\n",
       " <moabb.datasets.liu2024.Liu2024 at 0x19c3425acb0>,\n",
       " <moabb.datasets.upper_limb.Ofner2017 at 0x19c016c2ec0>,\n",
       " <moabb.datasets.physionet_mi.PhysionetMI at 0x19c0168a8f0>,\n",
       " <moabb.datasets.schirrmeister2017.Schirrmeister2017 at 0x19c01708490>,\n",
       " <moabb.datasets.bbci_eeg_fnirs.Shin2017A at 0x19c01709870>,\n",
       " <moabb.datasets.stieger2021.Stieger2021 at 0x19c0170a170>,\n",
       " <moabb.datasets.Weibo2014.Weibo2014 at 0x19c01709bd0>,\n",
       " <moabb.datasets.Zhou2016.Zhou2016 at 0x19c01708340>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagery_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e68937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagery_datasets[6].subject_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e84d7a",
   "metadata": {},
   "source": [
    "It is possible to get the data by using `.get_data()` function. Before using this function, which will download each dataset, is important to set the path directory, by using `moabb.utils.set_downalod_dir(path)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting download path. Sometimes this function does not work\n",
    "# moabb.utils.set_download_dir(path='./datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efaf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading each dataset\n",
    "#[dataset.get_data() for dataset in imagery_datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf79b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagery_datasets[0].get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaefe53d",
   "metadata": {},
   "source": [
    "### **4.2 Paradigms**\n",
    "\n",
    "As we explained before, there are four paradigms, which are: (1) Motor Imagery, (2) SSVEP, (3) P300, (4) CVEP, and (5) Resting State. Each of theses paradigms defines how raw MNE data will be processed and feed to the decoing algorithm.\n",
    "\n",
    "For Motor imagery paradigm:\n",
    "1. `MotorImagery()` - N Classes, N is the number of classes desired.\n",
    "2. `LeftRightImagery()`\n",
    "3. `FilterBankLeftRightImagery()`\n",
    "4. `FilterBankMotorImagery()`\n",
    "\n",
    "For P300 paradigm:\n",
    "1. `SinglePass()`\n",
    "2. `P300()`\n",
    "\n",
    "For SSVEP paradigm:\n",
    "1. `SSVEP()`\n",
    "2. `FilterBankSSVEP`\n",
    "\n",
    "For c-VEP Paradigms:\n",
    "1. `CVEP()`\n",
    "2. `FilterBankCVEP()`\n",
    "\n",
    "For Resting State Paradigms:\n",
    "1. `RestingStateToP300Adapter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e0edc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LeftRight for MotorImagery\n",
    "paradigm = moabb.paradigms.LeftRightImagery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c8b29d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<moabb.datasets.bnci.BNCI2014_001 object at 0x0000020B9034E680>, <moabb.datasets.bnci.BNCI2014_004 object at 0x0000020B9034E830>, <moabb.datasets.gigadb.Cho2017 object at 0x0000020B9034F790>, <moabb.datasets.mpi_mi.GrosseWentrup2009 object at 0x0000020BDB2DF700>, <moabb.datasets.Lee2019.Lee2019_MI object at 0x0000020B9034E800>, <moabb.datasets.liu2024.Liu2024 object at 0x0000020B9034C5E0>, <moabb.datasets.physionet_mi.PhysionetMI object at 0x0000020B9034C6D0>, <moabb.datasets.schirrmeister2017.Schirrmeister2017 object at 0x0000020B9034D5D0>, <moabb.datasets.bbci_eeg_fnirs.Shin2017A object at 0x0000020BF3695540>, <moabb.datasets.stieger2021.Stieger2021 object at 0x0000020B9034D090>, <moabb.datasets.Weibo2014.Weibo2014 object at 0x0000020B9034EE60>, <moabb.datasets.Zhou2016.Zhou2016 object at 0x0000020B9034C3D0>]\n"
     ]
    }
   ],
   "source": [
    "print(paradigm.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b4e78b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<moabb.datasets.gigadb.Cho2017 at 0x20b9034cb50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagery_datasets[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0292711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "c:\\Users\\erika\\Documents\\Code\\eeg-pyriemann-pipeline\\.venv\\lib\\site-packages\\moabb\\datasets\\preprocessing.py:278: UserWarning: warnEpochs <Epochs | 200 events (all good), 0 – 3 s (baseline off), ~150.2 MiB, data loaded,\n",
      " 'left_hand': 100\n",
      " 'right_hand': 100>\n",
      "  warn(f\"warnEpochs {epochs}\")\n",
      "Downloading data from 'https://s3.ap-northeast-1.wasabisys.com/gigadb-datasets/live/pub/10.5524/100001_101000/100295/mat_data/s02.mat' to file 'C:\\Users\\erika\\Documents\\Code\\eeg-pyriemann-pipeline\\notebooks\\.5524\\100001_101000\\100295\\mat_data\\s02.mat'.\n",
      "c:\\Users\\erika\\Documents\\Code\\eeg-pyriemann-pipeline\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 's3.ap-northeast-1.wasabisys.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "100%|########################################| 205M/205M [00:00<00:00, 136GB/s]\n",
      "SHA256 hash of downloaded file: 1ad1d82d9e409d85d520837377d88a89c086a4f526dba0ce0fe588b6e6e3659e\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Trials demeaned and stacked with zero buffer to create continuous data -- edge effects present\n",
      "c:\\Users\\erika\\Documents\\Code\\eeg-pyriemann-pipeline\\.venv\\lib\\site-packages\\moabb\\datasets\\preprocessing.py:278: UserWarning: warnEpochs <Epochs | 200 events (all good), 0 – 3 s (baseline off), ~150.2 MiB, data loaded,\n",
      " 'left_hand': 100\n",
      " 'right_hand': 100>\n",
      "  warn(f\"warnEpochs {epochs}\")\n"
     ]
    }
   ],
   "source": [
    "X, labels, meta = paradigm.get_data(dataset=imagery_datasets[6], subjects=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09cd8c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject session run\n",
       "0          1       0   0\n",
       "1          1       0   0\n",
       "2          1       0   0\n",
       "3          1       0   0\n",
       "4          1       0   0\n",
       "..       ...     ...  ..\n",
       "395        2       0   0\n",
       "396        2       0   0\n",
       "397        2       0   0\n",
       "398        2       0   0\n",
       "399        2       0   0\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b079c0",
   "metadata": {},
   "source": [
    "### **4.3 Pipeline**\n",
    "\n",
    "A pipeline in ML/DATA engineering refers to the end-to-end sequence of steps that data undergoes—from raw input to model predictions (or insights). Is this case we will be using for model training. We will me using scikit function `make_pipeline` for this purpouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(CSP(n_components=8), LDA())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424bb0ce",
   "metadata": {},
   "source": [
    "### **4.4 Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = moabb.evaluations.WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=[imagery_datasets[0]],\n",
    "    overwrite=True,\n",
    "    hdf5_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64398ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluation.process({\"csp+lda\": pipeline})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c831d",
   "metadata": {},
   "source": [
    "### **4.5 Statistics, visualization and utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd02294",
   "metadata": {},
   "outputs": [],
   "source": [
    "moabb.analysis.plotting.score_plot(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd46c1b",
   "metadata": {},
   "source": [
    "## **References**\n",
    "\n",
    "* [1] MOABB - https://moabb.neurotechx.com/docs/api.html\n",
    "* [2] Faker - https://faker-readthedocs-io.translate.goog/en/master/?_x_tr_sl=en&_x_tr_tl=pt&_x_tr_hl=pt&_x_tr_pto=tc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moabb-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
